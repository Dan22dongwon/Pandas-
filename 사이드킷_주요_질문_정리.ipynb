{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP32k/7ey/sVlx6yNqIkb7P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dan22dongwon/Pandas-sci-kit-learn/blob/main/%EC%82%AC%EC%9D%B4%EB%93%9C%ED%82%B7_%EC%A3%BC%EC%9A%94_%EC%A7%88%EB%AC%B8_%EC%A0%95%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#주요 질문 정리\n",
        "\n",
        "1.\t사이킷런의 주요 모듈과 클래스는 무엇인가요?\n",
        "2.\t사이킷런의 train_test_split 함수는 무엇을 하는 함수이며, 어떻게 사용하나요?\n",
        "3.\t사이킷런에서 데이터 전처리를 위해 어떤 도구들을 제공하나요? (예: StandardScaler, OneHotEncoder 등)\n",
        "4.\t사이킷런에서 교차 검증을 수행하기 위한 도구는 무엇이 있고, 어떻게 활용하나요? (예: cross_val_score, KFold 등)\n",
        "5.\t사이킷런에서 모델 평가를 위해 사용되는 일반적인 지표들은 어떤 것들이 있나요? (예: accuracy, precision, recall, F1-score 등)\n",
        "6.\t그리드 서치(GridSearchCV)는 무엇이며, 어떻게 사용하고 모델의 하이퍼파라미터 튜닝에 어떤 장점을 제공하나요?\n",
        "7.\t사이킷런에서 앙상블 모델을 구축하기 위해 어떤 도구들을 제공하나요? (예: VotingClassifier, BaggingClassifier, RandomForestClassifier 등)\n",
        "8.\t사이킷런에서 다양한 머신러닝 알고리즘을 지원하는데, 일반적인 알고리즘들은 어떤 것들이 있나요? (예: 선형 회귀, 로지스틱 회귀, 의사결정 트리, SVM, KNN 등)\n",
        "9. Validation set 이 뭔가요?\n"
      ],
      "metadata": {
        "id": "LMBkf5u8cL_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 주요한 사이킷런 모듈과 클래스는 다음과 같습니다:\n",
        "\n",
        "sklearn.datasets: 예제 데이터셋을 제공하는 모듈입니다.<br/>\n",
        "sklearn.model_selection: 모델 선택과 평가를 위한 도구를 제공하는 모듈입니다.<br/>\n",
        "sklearn.preprocessing: 데이터 전처리를 위한 도구를 제공하는 모듈입니다.<br/>\n",
        "sklearn.feature_extraction: 텍스트 데이터와 같은 특징을 추출하기 위한 도구를 제공하는 모듈입니다.<br/>\n",
        "sklearn.linear_model: 선형 회귀와 같은 선형 모델을 제공하는 모듈입니다.<br/>\n",
        "sklearn.tree: 의사결정 트리와 같은 결정 트리 기반 모델을 제공하는 모듈입니다.<br/>\n",
        "sklearn.ensemble: 앙상블 모델인 랜덤 포레스트와 그래디언트 부스팅 등을 제공하는 모듈입니다.<br/>\n",
        "sklearn.cluster: 군집화를 위한 도구를 제공하는 모듈입니다.<br/>\n",
        "sklearn.metrics: 모델의 성능 평가를 위한 지표와 함수를 제공하는 모듈입니다.<br/>\n",
        "sklearn.pipeline: 전처리와 모델 학습 등의 과정을 연결하여 실행할 수 있는 도구를 제공하는 모듈입니다.<br/>"
      ],
      "metadata": {
        "id": "ZjbbPsRecWYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.사이킷런의 train_test_split 함수는 무엇을 하는 함수이며, 어떻게 사용하나요?\n",
        "\n",
        "train_test_split은 사이킷런에서 제공하는 함수로, 데이터셋을 학습 데이터와 테스트 데이터로 분할하는 데 사용됩니다. 이를 통해 모델의 학습과 성능 평가를 독립적으로 수행할 수 있습니다.\n",
        "\n",
        "train_test_split 함수의 일반적인 사용법은 다음과 같습니다:\n",
        "\n",
        "```python\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "위 코드에서 X는 입력 특징 데이터, y는 해당하는 레이블 데이터를 나타냅니다. test_size는 테스트 데이터의 비율을 설정하는 매개변수로, 일반적으로 0.2 또는 0.3과 같은 값을 사용합니다. random_state는 데이터를 분할하는 데 사용되는 난수 발생기의 시드(seed)를 설정하는 매개변수입니다. 동일한 시드를 사용하면 매번 같은 데이터 분할이 이루어집니다.\n",
        "\n",
        "train_test_split 함수는 입력 데이터를 무작위로 섞은 후 주어진 비율에 따라 학습 데이터와 테스트 데이터로 분할합니다. 그 결과로 학습에 사용할 데이터인 X_train, y_train과 성능 평가에 사용할 데이터인 X_test, y_test를 반환합니다.\n",
        "\n",
        "이렇게 분할된 데이터를 사용하여 모델을 학습하고, 테스트 데이터에 대한 예측 및 성능 평가를 수행할 수 있습니다."
      ],
      "metadata": {
        "id": "d7mO-zbDcrkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.사이킷런에서 데이터 전처리를 위해 어떤 도구들을 제공하나요? (예: StandardScaler, OneHotEncoder 등)\n",
        "\n",
        "사이킷런의 preprocessing 모듈은 데이터 전처리를 위한 다양한 도구를 제공합니다. 몇 가지 예시를 살펴보면:\n",
        "\n",
        "StandardScaler: 데이터의 평균을 0, 표준 편차를 1로 만들어주는 표준화(standardization)를 수행합니다.\n",
        "```python\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "MinMaxScaler: 데이터를 최소값과 최대값 사이의 범위로 변환하여 스케일링합니다.\n",
        "```python\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "OneHotEncoder: 범주형 변수를 원-핫 인코딩하여 숫자형으로 변환합니다.\n",
        "```python\n",
        "Copy code\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "X_encoded = encoder.fit_transform(X)\n",
        "```\n",
        "LabelEncoder: 범주형 변수의 레이블을 숫자로 인코딩합니다.\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "```\n",
        "PolynomialFeatures: 다항 특성을 생성합니다.\n",
        "```python\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=2)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "```\n",
        "이 외에도 RobustScaler, PowerTransformer, LabelBinarizer 등 다양한 전처리 도구가 제공됩니다. 이러한 전처리 도구들을 사용하여 데이터를 변환하고 모델에 입력할 수 있습니다."
      ],
      "metadata": {
        "id": "3J-UcKV_dGyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.사이킷런에서 교차 검증을 수행하기 위한 도구는 무엇이 있고, 어떻게 활용하나요? (예: cross_val_score, KFold 등)\n",
        "\n",
        "사이킷런에서 교차 검증(cross-validation)을 수행하기 위한 도구는 model_selection 모듈에서 제공됩니다. 교차 검증은 데이터를 여러 개의 폴드(fold)로 나누어 각각을 테스트 데이터로 사용하고, 나머지 폴드들을 학습 데이터로 사용하여 모델의 성능을 평가하는 방법입니다. 이를 통해 모델의 일반화 성능을 더 정확하게 평가할 수 있습니다.\n",
        "\n",
        "사이킷런에서 교차 검증을 수행하기 위해 자주 사용되는 도구들 중 일부는 다음과 같습니다:\n",
        "\n",
        "cross_val_score: 주어진 모델과 데이터에 대해 교차 검증을 수행하여 정확도나 다른 지표를 반환합니다.\n",
        "python\n",
        "Copy code\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "KFold: K-fold 교차 검증을 수행하기 위한 클래스로, 데이터를 K개의 폴드로 나누는 인덱스를 생성합니다.\n",
        "```python\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for train_index, test_index in kfold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "```\n",
        "StratifiedKFold: 계층적 샘플링을 적용한 K-fold 교차 검증을 수행하기 위한 클래스로, 각 폴드 안의 클래스 비율을 유지합니다.\n",
        "```python\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for train_index, test_index in stratified_kfold.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "```\n",
        "교차 검증을 통해 모델의 성능을 평가할 수 있으며, 다양한 교차 검증 전략을 선택하여 데이터를 분할할 수 있습니다. 이를 통해 모델의 일반화 성능을 신뢰할 수 있는 방식으로 추정할 수 있습니다."
      ],
      "metadata": {
        "id": "xX_tH4c6dpAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.사이킷런에서 모델 평가를 위해 사용되는 일반적인 지표들은 어떤 것들이 있나요? (예: accuracy, precision, recall, F1-score 등)\n",
        "\n",
        "사이킷런에서는 다양한 모델의 성능을 평가하기 위한 지표들을 제공합니다. 이러한 지표들을 사용하여 모델의 예측 성능을 평가하고 비교할 수 있습니다. 몇 가지 일반적인 지표들은 다음과 같습니다:\n",
        "\n",
        "정확도 (Accuracy): 전체 예측 중 올바르게 분류된 샘플의 비율입니다.\n",
        "python\n",
        "Copy code\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "정밀도 (Precision): 양성으로 예측한 샘플 중 실제로 양성인 샘플의 비율입니다. 거짓 양성(FP)을 줄이는 데 초점을 둡니다.\n",
        "python\n",
        "Copy code\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "재현율 (Recall): 실제로 양성인 샘플 중 양성으로 예측된 샘플의 비율입니다. 거짓 음성(FN)을 줄이는 데 초점을 둡니다.\n",
        "python\n",
        "Copy code\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall = recall_score(y_true, y_pred)\n",
        "F1 스코어 (F1-score): 정밀도와 재현율의 조화 평균으로 계산되는 지표입니다. 정밀도와 재현율을 모두 고려합니다.\n",
        "```python\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "```\n",
        "로그 손실 (Log Loss): 다중 클래스 분류에서 예측의 확률 분포와 실제 클래스의 원-핫 인코딩을 비교하여 계산되는 손실 값입니다. 확률 값에 대한 가중치를 고려합니다.\n",
        "```python\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "log_loss = log_loss(y_true, y_pred_probabilities)\n",
        "```\n",
        "이 외에도 많은 평가 지표들이 사이킷런에서 제공되며, 문제의 특성과 목표에 따라 적절한 평가 지표를 선택할 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "User\n",
        "spilt 수치 정하는 방법과 이유\n",
        "ChatGPT\n",
        "데이터를 분할할 때 train_test_split 함수에서 test_size 매개변수를 사용하여 테스트 데이터의 비율을 지정할 수 있습니다. 이 값을 어떻게 정해야 하는지에 대한 일반적인 가이드라인은 다음과 같습니다:\n",
        "\n",
        "데이터의 크기: 데이터셋의 크기에 따라 테스트 데이터의 비율을 결정할 수 있습니다. 일반적으로 데이터가 많을수록 테스트 데이터의 비율을 높게 설정할 수 있습니다. 작은 데이터셋의 경우 테스트 데이터의 비율을 줄여서 모델의 성능을 더 정확하게 평가할 수 있습니다.\n",
        "\n",
        "목표: 모델의 최종 목표에 따라 테스트 데이터의 비율을 조정할 수 있습니다. 예를 들어, 모델의 성능을 정확하게 평가하려면 테스트 데이터의 비율을 높게 설정하여 모델이 다양한 데이터에서 일반화되는 능력을 확인할 수 있습니다. 반면에 모델의 훈련에 더 많은 데이터를 사용하고자 한다면 테스트 데이터의 비율을 낮게 설정할 수 있습니다.\n",
        "\n",
        "계획된 사용법: 모델을 실제로 어떻게 사용할지 고려하여 테스트 데이터의 비율을 선택할 수 있습니다. 예를 들어, 모델이 실제 배포되어 사용될 때에는 테스트 데이터의 비율을 더 낮게 설정하여 모델의 성능을 더 정확하게 평가하고자 할 수 있습니다.\n",
        "\n",
        "일반적으로는 0.2 또는 0.3과 같은 값으로 테스트 데이터의 비율을 설정하는 것이 일반적입니다. 이러한 비율은 경험적으로 적절한 값으로 여겨지며, 일반적으로 사용되는 기준이지만 절대적인 규칙은 아닙니다. 상황에 따라 테스트 데이터의 비율을 조정하여 모델의 성능 평가를 수행할 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FdzpDx2ueple"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.그리드 서치(GridSearchCV)는 무엇이며, 어떻게 사용하고 모델의 하이퍼파라미터 튜닝에 어떤 장점을 제공하나요?\n",
        "\n",
        "사이킷런에서는 모델의 하이퍼파라미터를 조정하고 최적의 조합을 찾기 위한 도구인 그리드 서치(Grid Search)와 랜덤 서치(Random Search)를 제공합니다.\n",
        "\n",
        "그리드 서치(Grid Search): 가능한 모든 조합의 하이퍼파라미터 값을 시도하여 최적의 조합을 찾는 방법입니다. 사전에 설정한 하이퍼파라미터들의 모든 조합에 대해 교차 검증을 수행하여 최상의 성능을 갖는 조합을 선택합니다. GridSearchCV 클래스를 사용하여 구현할 수 있습니다.\n",
        "```python\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'param1': [value1, value2, ...],\n",
        "    'param2': [value1, value2, ...],\n",
        "    ...\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X, y)\n",
        "best_params = grid_search.best_params_\n",
        "```\n",
        "랜덤 서치(Random Search): 미리 지정한 하이퍼파라미터 값들 중에서 랜덤하게 조합을 선택하여 성능을 평가하는 방법입니다. 그리드 서치와 달리 가능한 모든 조합을 시도하지 않고 랜덤한 조합을 선택하므로 탐색 범위가 넓고 계산 비용이 큰 경우 유용합니다. RandomizedSearchCV 클래스를 사용하여 구현할 수 있습니다.\n",
        "```python\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist = {\n",
        "    'param1': [value1, value2, ...],\n",
        "    'param2': [value1, value2, ...],\n",
        "    ...\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(model, param_dist, n_iter=10, cv=5)\n",
        "random_search.fit(X, y)\n",
        "best_params = random_search.best_params_\n",
        "```\n",
        "두 방법 모두 지정한 하이퍼파라미터 값들을 사용하여 교차 검증을 수행하고, 최적의 조합을 선택합니다. 그리드 서치는 가능한 조합을 모두 탐색하기 때문에 모든 하이퍼파라미터 값을 시도하지만, 랜덤 서치는 일부 조합만 선택하여 탐색하기 때문에 계산 비용이 적게 듭니다. 선택할 방법은 문제의 복잡도와 하이퍼파라미터 탐색 공간의 크기에 따라 달라집니다."
      ],
      "metadata": {
        "id": "pkmxY4_2fa5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.사이킷런에서 앙상블 모델을 구축하기 위해 어떤 도구들을 제공하나요? (예: VotingClassifier, BaggingClassifier, RandomForestClassifier 등)\n",
        "\n",
        "사이킷런에서는 모델의 성능을 평가하기 위해 교차 검증(Cross-Validation)을 사용할 수 있습니다. 교차 검증은 데이터를 여러 개의 부분 집합으로 나누어 각각을 학습과 평가에 사용하여 모델의 일반화 성능을 추정하는 방법입니다.\n",
        "\n",
        "가장 일반적으로 사용되는 교차 검증 기법은 K-Fold 교차 검증입니다. K-Fold 교차 검증은 데이터를 K개의 서로 다른 부분 집합으로 나누고, 각 부분 집합을 한 번씩 테스트 데이터로 사용하고 나머지 부분 집합을 학습 데이터로 사용하여 K번의 모델 학습과 평가를 수행합니다. 이렇게 K번의 평가 결과를 평균하여 최종 성능을 추정합니다. 사이킷런에서는 cross_val_score 함수를 사용하여 K-Fold 교차 검증을 수행할 수 있습니다.\n",
        "\n",
        "```python\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=K)\n",
        "```\n",
        "model: 평가할 모델 객체\n",
        "X: 피처 데이터\n",
        "y: 타깃 데이터\n",
        "cv: Fold의 개수 K\n",
        "cross_val_score 함수는 K개의 Fold에서 모델을 학습하고 평가한 성능 점수를 반환합니다. 기본적으로 분류 모델의 경우 정확도(Accuracy)를 평가 지표로 사용하고, 회귀 모델의 경우 평균 제곱 오차(Mean Squared Error)를 사용합니다. cv 매개변수에 Fold의 개수 K를 지정하여 원하는 Fold 수로 교차 검증을 수행할 수 있습니다.\n",
        "\n",
        "교차 검증은 모델의 성능을 더 정확하게 추정할 수 있으며, 데이터에 대한 모델의 일반화 성능을 더 신뢰할 수 있도록 도와줍니다. 또한, 과적합을 방지하고 모델의 일반화 능력을 개선하는 데에도 도움을 줍니다."
      ],
      "metadata": {
        "id": "Hc4t8eO-fyDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. 사이킷런에서 다양한 머신러닝 알고리즘을 지원하는데, 일반적인 알고리즘들은 어떤 것들이 있나요? (예: 선형 회귀, 로지스틱 회귀, 의사결정 트리, SVM, KNN 등)\n",
        "\n",
        "사이킷런에서는 모델의 성능을 평가하기 위해 다양한 지표를 제공합니다. 이러한 평가 지표를 사용하여 모델의 성능을 측정하고 비교할 수 있습니다. 몇 가지 일반적으로 사용되는 평가 지표는 다음과 같습니다:\n",
        "\n",
        "정확도(Accuracy): 정확도는 전체 샘플 중에서 올바르게 분류된 샘플의 비율을 나타냅니다. 이는 분류 문제에서 가장 기본적인 평가 지표입니다. accuracy_score 함수를 사용하여 계산할 수 있습니다.\n",
        "\n",
        "**정밀도(Precision)**와 재현율(Recall): 이진 분류 문제에서 주로 사용되는 평가 지표로, 정밀도는 양성으로 예측한 샘플 중에서 실제로 양성인 샘플의 비율을 나타내며, 재현율은 실제로 양성인 샘플 중에서 양성으로 예측한 샘플의 비율을 나타냅니다. precision_score와 recall_score 함수를 사용하여 계산할 수 있습니다.\n",
        "\n",
        "F1 스코어(F1 Score): 정밀도와 재현율의 조화 평균인 F1 스코어는 정밀도와 재현율을 동시에 고려하여 모델의 성능을 평가하는 지표입니다. f1_score 함수를 사용하여 계산할 수 있습니다.\n",
        "\n",
        "로그 손실(Log Loss): 로그 손실은 확률 예측 모델의 성능을 평가하는 지표로, 모델의 예측 확률과 실제 레이블 사이의 차이를 계산합니다. 로그 손실 값이 작을수록 모델의 예측이 정확하다고 판단됩니다. log_loss 함수를 사용하여 계산할 수 있습니다.\n",
        "\n",
        "평균 제곱 오차(Mean Squared Error, MSE): 회귀 문제에서 주로 사용되는 평가 지표로, 예측값과 실제값 간의 오차 제곱의 평균을 계산합니다. MSE 값이 작을수록 모델의 예측이 정확하다고 판단됩니다. mean_squared_error 함수를 사용하여 계산할 수 있습니다."
      ],
      "metadata": {
        "id": "iMtD568vgOtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9.Validation set 이 뭔가요?\n",
        "\n",
        "Validation set은 모델의 성능을 평가하고 모델의 하이퍼파라미터 튜닝 등에 사용되는 데이터 세트입니다. 일반적으로 학습 데이터는 훈련 데이터와 검증 데이터로 나누어 사용합니다.\n",
        "\n",
        "훈련 데이터는 모델을 학습시키는 데 사용되고, 검증 데이터는 모델의 성능을 평가하는 데 사용됩니다. 검증 데이터를 통해 모델의 성능을 모니터링하면서 모델의 일반화 성능을 추정하고, 과적합을 방지하거나 모델의 성능을 개선하기 위해 하이퍼파라미터를 조정할 수 있습니다.\n",
        "\n",
        "일반적으로 데이터는 훈련 데이터, 검증 데이터, 테스트 데이터로 나뉘며, 주로 다음과 같은 비율로 분할됩니다:\n",
        "\n",
        "훈련 데이터 (Training set): 모델을 학습시키는 데 사용되는 데이터로, 일반적으로 전체 데이터의 60-80% 정도를 할당합니다.\n",
        "검증 데이터 (Validation set): 모델의 성능을 평가하고 하이퍼파라미터를 조정하는 데 사용되는 데이터로, 일반적으로 전체 데이터의 10-20% 정도를 할당합니다.\n",
        "테스트 데이터 (Test set): 최종 모델의 성능을 평가하기 위해 사용되는 데이터로, 모델 학습 과정에 직접적으로 사용되지 않습니다. 일반적으로 전체 데이터의 나머지 10-30%를 할당합니다.\n",
        "Validation set은 모델의 성능을 평가하고 최적의 모델을 선택하는 데 중요한 역할을 합니다. 검증 데이터를 통해 모델의 일반화 성능을 추정하고, 다양한 모델 또는 하이퍼파라미터 조합을 평가하여 최상의 모델을 선택할 수 있습니다."
      ],
      "metadata": {
        "id": "TWyzeHHApt-P"
      }
    }
  ]
}